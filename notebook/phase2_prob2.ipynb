{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, PolynomialFeatures, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFIGURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/raw_data/phase-2/prob-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = 'raw_train.parquet'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "      <th>feature22</th>\n",
       "      <th>feature23</th>\n",
       "      <th>feature24</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>feature35</th>\n",
       "      <th>feature36</th>\n",
       "      <th>feature37</th>\n",
       "      <th>feature38</th>\n",
       "      <th>feature39</th>\n",
       "      <th>feature40</th>\n",
       "      <th>feature41</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041847</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2438.0</td>\n",
       "      <td>19266.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.538438e+05</td>\n",
       "      <td>3.591177e+06</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.153722</td>\n",
       "      <td>1.058410</td>\n",
       "      <td>68.764188</td>\n",
       "      <td>66.421092</td>\n",
       "      <td>255.0</td>\n",
       "      <td>3.898436e+09</td>\n",
       "      <td>1.827204e+09</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>64.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.089133</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>FIN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1684.0</td>\n",
       "      <td>10168.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.148804e+04</td>\n",
       "      <td>7.054418e+04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>83.751772</td>\n",
       "      <td>64.035706</td>\n",
       "      <td>9346.434820</td>\n",
       "      <td>8182.385202</td>\n",
       "      <td>255.0</td>\n",
       "      <td>3.051186e+09</td>\n",
       "      <td>9.067852e+08</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>120.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3924.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>INT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.280000e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.467246</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2618.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>1.308574e+04</td>\n",
       "      <td>3.413197e+03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>133.386003</td>\n",
       "      <td>124.152453</td>\n",
       "      <td>7744.976658</td>\n",
       "      <td>198.329344</td>\n",
       "      <td>255.0</td>\n",
       "      <td>2.477915e+09</td>\n",
       "      <td>1.653923e+09</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.173821</td>\n",
       "      <td>0.101319</td>\n",
       "      <td>0.072502</td>\n",
       "      <td>218.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Denial of Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000927</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>CON</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.609493e+05</td>\n",
       "      <td>6.990291e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1 feature2 feature3 feature4  feature5  feature6  feature7  \\\n",
       "0  0.041847      tcp        -      FIN      38.0      40.0    2438.0   \n",
       "1  1.089133      tcp     http      FIN      14.0      18.0    1684.0   \n",
       "2  0.000002      udp      dns      INT       2.0       0.0     114.0   \n",
       "3  1.467246      tcp      ftp      FIN      12.0      12.0    2618.0   \n",
       "4  0.000927      udp      dns      CON       2.0       2.0     130.0   \n",
       "\n",
       "   feature8  feature9  feature10     feature11     feature12  feature13  \\\n",
       "0   19266.0      31.0       29.0  4.538438e+05  3.591177e+06        7.0   \n",
       "1   10168.0      31.0       29.0  1.148804e+04  7.054418e+04        3.0   \n",
       "2       0.0     254.0        0.0  2.280000e+08  0.000000e+00        0.0   \n",
       "3     682.0     254.0      252.0  1.308574e+04  3.413197e+03        3.0   \n",
       "4     162.0      31.0       29.0  5.609493e+05  6.990291e+05        0.0   \n",
       "\n",
       "   feature14   feature15   feature16    feature17    feature18  feature19  \\\n",
       "0       13.0    1.153722    1.058410    68.764188    66.421092      255.0   \n",
       "1        5.0   83.751772   64.035706  9346.434820  8182.385202      255.0   \n",
       "2        0.0    0.002000    0.000000     0.000000     0.000000        0.0   \n",
       "3        4.0  133.386003  124.152453  7744.976658   198.329344      255.0   \n",
       "4        0.0    0.002000    0.003000     0.000000     0.000000        0.0   \n",
       "\n",
       "      feature20     feature21  feature22  feature23  feature24  feature25  \\\n",
       "0  3.898436e+09  1.827204e+09      255.0   0.000707   0.000566   0.000141   \n",
       "1  3.051186e+09  9.067852e+08      255.0   0.000665   0.000523   0.000142   \n",
       "2  0.000000e+00  0.000000e+00        0.0   0.000000   0.000000   0.000000   \n",
       "3  2.477915e+09  1.653923e+09      255.0   0.173821   0.101319   0.072502   \n",
       "4  0.000000e+00  0.000000e+00        0.0   0.000000   0.000000   0.000000   \n",
       "\n",
       "   feature26  feature27  feature28  feature29  feature30  feature31  \\\n",
       "0       64.0      482.0        0.0        0.0        6.0        0.0   \n",
       "1      120.0      565.0        1.0     3924.0        1.0        0.0   \n",
       "2       57.0        0.0        0.0        0.0       25.0        2.0   \n",
       "3      218.0       57.0        0.0        0.0        3.0        1.0   \n",
       "4       65.0       81.0        0.0        0.0        1.0        0.0   \n",
       "\n",
       "   feature32  feature33  feature34  feature35  feature36  feature37  \\\n",
       "0        5.0        1.0        1.0        1.0        0.0        0.0   \n",
       "1        2.0        1.0        1.0        2.0        0.0        0.0   \n",
       "2       18.0       17.0       17.0       25.0        0.0        0.0   \n",
       "3        1.0        1.0        1.0        3.0        0.0        0.0   \n",
       "4        3.0        1.0        1.0        2.0        0.0        0.0   \n",
       "\n",
       "   feature38  feature39  feature40  feature41              label  \n",
       "0        0.0        2.0       11.0        0.0             Normal  \n",
       "1        1.0        2.0        1.0        0.0             Normal  \n",
       "2        0.0       17.0       25.0        0.0              Other  \n",
       "3        0.0        2.0        3.0        0.0  Denial of Service  \n",
       "4        0.0        1.0        4.0        0.0             Normal  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_parquet(f'{DATA_PATH}/{DATA_FILE}', engine='fastparquet')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train data: 0\n"
     ]
    }
   ],
   "source": [
    "print('Missing values in train data:', df_train.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61841 entries, 0 to 61840\n",
      "Data columns (total 42 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   feature1   61841 non-null  float64\n",
      " 1   feature2   61841 non-null  object \n",
      " 2   feature3   61841 non-null  object \n",
      " 3   feature4   61841 non-null  object \n",
      " 4   feature5   61841 non-null  float64\n",
      " 5   feature6   61841 non-null  float64\n",
      " 6   feature7   61841 non-null  float64\n",
      " 7   feature8   61841 non-null  float64\n",
      " 8   feature9   61841 non-null  float64\n",
      " 9   feature10  61841 non-null  float64\n",
      " 10  feature11  61841 non-null  float64\n",
      " 11  feature12  61841 non-null  float64\n",
      " 12  feature13  61841 non-null  float64\n",
      " 13  feature14  61841 non-null  float64\n",
      " 14  feature15  61841 non-null  float64\n",
      " 15  feature16  61841 non-null  float64\n",
      " 16  feature17  61841 non-null  float64\n",
      " 17  feature18  61841 non-null  float64\n",
      " 18  feature19  61841 non-null  float64\n",
      " 19  feature20  61841 non-null  float64\n",
      " 20  feature21  61841 non-null  float64\n",
      " 21  feature22  61841 non-null  float64\n",
      " 22  feature23  61841 non-null  float64\n",
      " 23  feature24  61841 non-null  float64\n",
      " 24  feature25  61841 non-null  float64\n",
      " 25  feature26  61841 non-null  float64\n",
      " 26  feature27  61841 non-null  float64\n",
      " 27  feature28  61841 non-null  float64\n",
      " 28  feature29  61841 non-null  float64\n",
      " 29  feature30  61841 non-null  float64\n",
      " 30  feature31  61841 non-null  float64\n",
      " 31  feature32  61841 non-null  float64\n",
      " 32  feature33  61841 non-null  float64\n",
      " 33  feature34  61841 non-null  float64\n",
      " 34  feature35  61841 non-null  float64\n",
      " 35  feature36  61841 non-null  float64\n",
      " 36  feature37  61841 non-null  float64\n",
      " 37  feature38  61841 non-null  float64\n",
      " 38  feature39  61841 non-null  float64\n",
      " 39  feature40  61841 non-null  float64\n",
      " 40  feature41  61841 non-null  float64\n",
      " 41  label      61841 non-null  object \n",
      "dtypes: float64(38), object(4)\n",
      "memory usage: 19.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal                   22390\n",
       "Other                    13963\n",
       "Exploits                 10864\n",
       "Denial of Service         9585\n",
       "Information Gathering     4081\n",
       "Malware                    958\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.copy()\n",
    "y = X.pop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = pd.Series(label_encoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Normal', 'Normal'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform([4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y,\n",
    "                                                  test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline score: 0.5572445019404916\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "oof_preds = pd.Series(index=X_train.index, dtype='float64')\n",
    "\n",
    "for n_fold, (train_index, test_index) in enumerate(kf.split(X_train, y_train)):\n",
    "    X_train_kf, X_val_kf = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_kf, y_val_kf = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    # Select only numerical features\n",
    "    X_train_kf = X_train_kf.select_dtypes(include='number')\n",
    "    X_val_kf = X_val_kf.select_dtypes(include='number')\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train_kf, y_train_kf)\n",
    "\n",
    "    oof_preds.iloc[test_index] = model.predict(X_val_kf)\n",
    "\n",
    "print('Baseline score:', accuracy_score(y_train, oof_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.5547740318538281\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train.select_dtypes(include='number'), y_train)\n",
    "\n",
    "print('Test score:', accuracy_score(y_val, model.predict(X_val.select_dtypes(include='number'))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Test score***: 0.56<br>\n",
    "***Response time***: 1.40"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline score: 0.7405198900388098\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "oof_preds = pd.Series(index=X_train.index, dtype='float64')\n",
    "\n",
    "for n_fold, (train_index, test_index) in enumerate(kf.split(X_train, y_train)):\n",
    "    X_train_kf, X_oof_kf = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_kf, y_oof_kf = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    # Select only numerical features\n",
    "    X_train_kf = X_train_kf.select_dtypes(include='number')\n",
    "    X_oof_kf = X_oof_kf.select_dtypes(include='number')\n",
    "\n",
    "    X_train_kf = scaler.fit_transform(X_train_kf)\n",
    "    X_oof_kf = scaler.transform(X_oof_kf)\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train_kf, y_train_kf)\n",
    "\n",
    "    oof_preds.iloc[test_index] = model.predict(X_oof_kf)\n",
    "\n",
    "print('Baseline score:', accuracy_score(y_train, oof_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.7403185382811869\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train.select_dtypes(include='number'))\n",
    "X_val_scaled = scaler.transform(X_val.select_dtypes(include='number'))\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Validation score:', accuracy_score(y_val, model.predict(X_val_scaled)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\"feature2\", \"feature3\", \"feature4\"]\n",
    "numerical_columns = [\"feature1\", \"feature5\", \"feature6\", \"feature7\", \"feature8\", \"feature9\",\n",
    "                    \"feature10\", \"feature11\", \"feature12\", \"feature13\", \"feature14\", \"feature15\",\n",
    "                    \"feature16\", \"feature17\", \"feature18\", \"feature19\", \"feature20\", \"feature21\",\n",
    "                    \"feature22\", \"feature23\", \"feature24\", \"feature25\", \"feature26\", \"feature27\",\n",
    "                    \"feature28\", \"feature29\", \"feature30\", \"feature31\", \"feature32\", \"feature33\",\n",
    "                    \"feature34\", \"feature35\", \"feature36\", \"feature37\", \"feature38\", \"feature39\",\n",
    "                    \"feature40\", \"feature41\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_kf.loc[:, categorical_columns] = encoder.fit_transform(X_train_kf[categorical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:8: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_train_kf.loc[:, categorical_columns] = encoder.fit_transform(X_train_kf[categorical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_oof_kf.loc[:, categorical_columns] = encoder.transform(X_oof_kf[categorical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:9: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_oof_kf.loc[:, categorical_columns] = encoder.transform(X_oof_kf[categorical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_kf.loc[:, numerical_columns] = scaler.fit_transform(X_train_kf[numerical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_oof_kf.loc[:, numerical_columns] = scaler.transform(X_oof_kf[numerical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_kf.loc[:, categorical_columns] = encoder.fit_transform(X_train_kf[categorical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:8: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_train_kf.loc[:, categorical_columns] = encoder.fit_transform(X_train_kf[categorical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_oof_kf.loc[:, categorical_columns] = encoder.transform(X_oof_kf[categorical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:9: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_oof_kf.loc[:, categorical_columns] = encoder.transform(X_oof_kf[categorical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_kf.loc[:, numerical_columns] = scaler.fit_transform(X_train_kf[numerical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_oof_kf.loc[:, numerical_columns] = scaler.transform(X_oof_kf[numerical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_kf.loc[:, categorical_columns] = encoder.fit_transform(X_train_kf[categorical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:8: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_train_kf.loc[:, categorical_columns] = encoder.fit_transform(X_train_kf[categorical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_oof_kf.loc[:, categorical_columns] = encoder.transform(X_oof_kf[categorical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:9: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_oof_kf.loc[:, categorical_columns] = encoder.transform(X_oof_kf[categorical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_kf.loc[:, numerical_columns] = scaler.fit_transform(X_train_kf[numerical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_oof_kf.loc[:, numerical_columns] = scaler.transform(X_oof_kf[numerical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_kf.loc[:, categorical_columns] = encoder.fit_transform(X_train_kf[categorical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:8: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_train_kf.loc[:, categorical_columns] = encoder.fit_transform(X_train_kf[categorical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_oof_kf.loc[:, categorical_columns] = encoder.transform(X_oof_kf[categorical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:9: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_oof_kf.loc[:, categorical_columns] = encoder.transform(X_oof_kf[categorical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_kf.loc[:, numerical_columns] = scaler.fit_transform(X_train_kf[numerical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_oof_kf.loc[:, numerical_columns] = scaler.transform(X_oof_kf[numerical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_kf.loc[:, categorical_columns] = encoder.fit_transform(X_train_kf[categorical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:8: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_train_kf.loc[:, categorical_columns] = encoder.fit_transform(X_train_kf[categorical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_oof_kf.loc[:, categorical_columns] = encoder.transform(X_oof_kf[categorical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:9: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_oof_kf.loc[:, categorical_columns] = encoder.transform(X_oof_kf[categorical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_kf.loc[:, numerical_columns] = scaler.fit_transform(X_train_kf[numerical_columns])\n",
      "C:\\Users\\tdbui\\AppData\\Local\\Temp\\ipykernel_9980\\677522234.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_oof_kf.loc[:, numerical_columns] = scaler.transform(X_oof_kf[numerical_columns])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline score: 0.7565895860284605\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "oof_preds = pd.Series(index=X_train.index, dtype='float64')\n",
    "\n",
    "for n_fold, (train_index, test_index) in enumerate(kf.split(X_train, y_train)):\n",
    "    X_train_kf, X_oof_kf = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_kf, y_oof_kf = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    X_train_kf_num = scaler.fit_transform(X_train_kf[numerical_columns])\n",
    "    X_oof_kf_num = scaler.transform(X_oof_kf[numerical_columns])\n",
    "\n",
    "    X_train_kf_cat = encoder.fit_transform(X_train_kf[categorical_columns])\n",
    "    X_oof_kf_cat = encoder.transform(X_oof_kf[categorical_columns])\n",
    "\n",
    "    model = LogisticRegression(max_iter=10000)\n",
    "    model.fit(np.concatenate((X_train_kf_num, X_train_kf_cat), axis=1), y_train_kf)\n",
    "\n",
    "    oof_preds.iloc[test_index] = model.predict(np.concatenate((X_oof_kf_num, X_oof_kf_cat), axis=1))\n",
    "\n",
    "print('Baseline score:', accuracy_score(y_train, oof_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.7551135904276821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MLOps-Marathon-2023\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train_num = scaler.fit_transform(X_train[numerical_columns])\n",
    "X_val_num = scaler.transform(X_val[numerical_columns])\n",
    "\n",
    "X_train_cat = encoder.fit_transform(X_train[categorical_columns])\n",
    "X_val_cat = encoder.transform(X_val[categorical_columns])\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(np.concatenate((X_train_num, X_train_cat), axis=1), y_train)\n",
    "\n",
    "print('Validation score:', accuracy_score(y_val, model.predict(np.concatenate((X_val_num, X_val_cat), axis=1))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\"feature2\", \"feature3\", \"feature4\"]\n",
    "numerical_columns = [\"feature1\", \"feature5\", \"feature6\", \"feature7\", \"feature8\", \"feature9\",\n",
    "                    \"feature10\", \"feature11\", \"feature12\", \"feature13\", \"feature14\", \"feature15\",\n",
    "                    \"feature16\", \"feature17\", \"feature18\", \"feature19\", \"feature20\", \"feature21\",\n",
    "                    \"feature22\", \"feature23\", \"feature24\", \"feature25\", \"feature26\", \"feature27\",\n",
    "                    \"feature28\", \"feature29\", \"feature30\", \"feature31\", \"feature32\", \"feature33\",\n",
    "                    \"feature34\", \"feature35\", \"feature36\", \"feature37\", \"feature38\", \"feature39\",\n",
    "                    \"feature40\", \"feature41\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline score: 0.7709007115135834\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "oof_preds = pd.Series(index=X_train.index, dtype='float64')\n",
    "\n",
    "for n_fold, (train_index, test_index) in enumerate(kf.split(X_train, y_train)):\n",
    "    X_train_kf, X_oof_kf = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_kf, y_oof_kf = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    X_train_cat_kf = encoder.fit_transform(X_train_kf[categorical_columns])\n",
    "    X_oof_cat_kf = encoder.transform(X_oof_kf[categorical_columns])\n",
    "\n",
    "    X_train_kf = scaler.fit_transform(np.concatenate([X_train_kf[numerical_columns], X_train_cat_kf], axis=1))\n",
    "    X_oof_kf = scaler.transform(np.concatenate([X_oof_kf[numerical_columns], X_oof_cat_kf], axis=1))\n",
    "\n",
    "    model = LogisticRegression(max_iter=10000)\n",
    "    model.fit(X_train_kf, y_train_kf)\n",
    "\n",
    "    oof_preds.iloc[test_index] = model.predict(X_oof_kf)\n",
    "\n",
    "print('Baseline score:', accuracy_score(y_train, oof_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict time: 0.010011434555053711\n",
      "Validation score: 0.7711213517665131\n"
     ]
    }
   ],
   "source": [
    "X_train_cat = encoder.fit_transform(X_train[categorical_columns])\n",
    "X_val_cat = encoder.transform(X_val[categorical_columns])\n",
    "\n",
    "X_train_solution_3 = scaler.fit_transform(np.concatenate([X_train[numerical_columns], X_train_cat], axis=1))\n",
    "X_val_solution_3 = scaler.transform(np.concatenate([X_val[numerical_columns], X_val_cat], axis=1))\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_solution_3, y_train)\n",
    "t1 = time.time()\n",
    "y_pred = model.predict(X_val_solution_3)\n",
    "print('Predict time:' ,time.time() - t1)\n",
    "\n",
    "print('Validation score:', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'linear model': LogisticRegression(max_iter=10000),\n",
    "    'random forest': RandomForestClassifier(random_state=42),\n",
    "    'xgboost': XGBClassifier(random_state=42, tree_method='gpu_hist'),\n",
    "    'svm': SVC(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting linear model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:49<00:00, 21.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for linear model: 0.7709007115135834\n",
      "Fitting random forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:48<00:00,  9.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for random forest: 0.813106403622251\n",
      "Fitting xgboost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:29<00:00,  5.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for xgboost: 0.8243450840879689\n",
      "Fitting svm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [17:16<00:00, 207.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for svm: 0.7563268111254852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name in models:\n",
    "    print(f'Fitting {model_name}...')\n",
    "    kf = KFold(n_splits=5)\n",
    "    oof_preds = pd.Series(index=X_train.index, dtype='float64')\n",
    "    for train_index, test_index in tqdm(kf.split(X_train, y_train), total=kf.get_n_splits()):\n",
    "        X_train_kf, X_oof_kf = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_kf, y_oof_kf = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        X_train_cat_kf = encoder.fit_transform(X_train_kf[categorical_columns])\n",
    "        X_oof_cat_kf = encoder.transform(X_oof_kf[categorical_columns])\n",
    "\n",
    "        X_train_kf = scaler.fit_transform(np.concatenate([X_train_kf[numerical_columns], X_train_cat_kf], axis=1))\n",
    "        X_oof_kf = scaler.transform(np.concatenate([X_oof_kf[numerical_columns], X_oof_cat_kf], axis=1))\n",
    "\n",
    "        model = models[model_name]\n",
    "        model.fit(X_train_kf, y_train_kf)\n",
    "\n",
    "        oof_preds.iloc[test_index] = model.predict(X_oof_kf)\n",
    "    print(f'Score for {model_name}:', accuracy_score(y_train, oof_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict time: 0.029999732971191406\n",
      "Validation score: 0.8270676691729323\n"
     ]
    }
   ],
   "source": [
    "X_train_cat = encoder.fit_transform(X_train[categorical_columns])\n",
    "X_val_cat = encoder.transform(X_val[categorical_columns])\n",
    "\n",
    "X_train_num = scaler.fit_transform(X_train[numerical_columns])\n",
    "X_val_num = scaler.transform(X_val[numerical_columns])\n",
    "\n",
    "X_train_solution_3 = np.concatenate([X_train_num, X_train_cat], axis=1)\n",
    "X_val_solution_3 = np.concatenate([X_val_num, X_val_cat], axis=1)\n",
    "\n",
    "model = XGBClassifier(random_state=42)\n",
    "model.fit(X_train_solution_3, y_train)\n",
    "\n",
    "t1 = time.time()\n",
    "y_pred = model.predict(X_val_solution_3)\n",
    "print('Predict time:' ,time.time() - t1)\n",
    "\n",
    "print('Validation score:', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('model2.sav', 'wb'))\n",
    "pickle.dump(encoder, open('encoder2.sav', 'wb'))\n",
    "pickle.dump(scaler, open('scaler2.sav', 'wb'))\n",
    "pickle.dump(label_encoder, open('label_encoder2.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Denial of Service', 'Exploits', 'Information Gathering',\n",
       "       'Malware', 'Normal', 'Other'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "a= [random.randint(0, 5) for _ in range(200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = {i: j for i, j in enumerate(label_encoder.classes_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Denial of Service',\n",
       " 1: 'Exploits',\n",
       " 2: 'Information Gathering',\n",
       " 3: 'Malware',\n",
       " 4: 'Normal',\n",
       " 5: 'Other'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in a:\n",
    "    lookup[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 997 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Normal', 'Exploits', 'Exploits', 'Exploits', 'Denial of Service',\n",
       "       'Other', 'Normal', 'Denial of Service', 'Denial of Service',\n",
       "       'Malware', 'Malware', 'Malware', 'Normal', 'Other',\n",
       "       'Denial of Service', 'Denial of Service', 'Malware', 'Normal',\n",
       "       'Information Gathering', 'Denial of Service', 'Other', 'Normal',\n",
       "       'Malware', 'Other', 'Other', 'Other', 'Malware', 'Normal',\n",
       "       'Information Gathering', 'Exploits', 'Other', 'Exploits',\n",
       "       'Denial of Service', 'Malware', 'Information Gathering', 'Malware',\n",
       "       'Malware', 'Exploits', 'Information Gathering', 'Malware',\n",
       "       'Denial of Service', 'Exploits', 'Other', 'Denial of Service',\n",
       "       'Exploits', 'Exploits', 'Denial of Service',\n",
       "       'Information Gathering', 'Denial of Service', 'Malware', 'Normal',\n",
       "       'Information Gathering', 'Denial of Service', 'Exploits',\n",
       "       'Malware', 'Malware', 'Malware', 'Denial of Service', 'Exploits',\n",
       "       'Normal', 'Denial of Service', 'Information Gathering', 'Exploits',\n",
       "       'Other', 'Information Gathering', 'Normal', 'Malware', 'Normal',\n",
       "       'Exploits', 'Denial of Service', 'Denial of Service', 'Normal',\n",
       "       'Information Gathering', 'Malware', 'Exploits',\n",
       "       'Denial of Service', 'Denial of Service', 'Other',\n",
       "       'Denial of Service', 'Information Gathering',\n",
       "       'Information Gathering', 'Exploits', 'Other', 'Other', 'Normal',\n",
       "       'Malware', 'Other', 'Normal', 'Information Gathering', 'Exploits',\n",
       "       'Other', 'Other', 'Other', 'Denial of Service',\n",
       "       'Information Gathering', 'Malware', 'Denial of Service', 'Normal',\n",
       "       'Information Gathering', 'Normal', 'Information Gathering',\n",
       "       'Malware', 'Malware', 'Normal', 'Denial of Service',\n",
       "       'Information Gathering', 'Normal', 'Exploits', 'Exploits',\n",
       "       'Denial of Service', 'Malware', 'Information Gathering', 'Other',\n",
       "       'Information Gathering', 'Information Gathering',\n",
       "       'Information Gathering', 'Information Gathering', 'Exploits',\n",
       "       'Other', 'Malware', 'Other', 'Denial of Service',\n",
       "       'Information Gathering', 'Malware', 'Normal', 'Other',\n",
       "       'Information Gathering', 'Malware', 'Denial of Service',\n",
       "       'Information Gathering', 'Normal', 'Other', 'Normal', 'Malware',\n",
       "       'Normal', 'Other', 'Exploits', 'Denial of Service', 'Malware',\n",
       "       'Normal', 'Normal', 'Normal', 'Other', 'Denial of Service',\n",
       "       'Normal', 'Other', 'Information Gathering', 'Malware',\n",
       "       'Denial of Service', 'Other', 'Denial of Service', 'Exploits',\n",
       "       'Exploits', 'Normal', 'Exploits', 'Information Gathering',\n",
       "       'Information Gathering', 'Malware', 'Denial of Service',\n",
       "       'Information Gathering', 'Information Gathering', 'Malware',\n",
       "       'Normal', 'Exploits', 'Other', 'Normal', 'Normal',\n",
       "       'Information Gathering', 'Denial of Service',\n",
       "       'Information Gathering', 'Denial of Service',\n",
       "       'Information Gathering', 'Other', 'Exploits',\n",
       "       'Information Gathering', 'Other', 'Other', 'Information Gathering',\n",
       "       'Malware', 'Exploits', 'Malware', 'Information Gathering',\n",
       "       'Denial of Service', 'Exploits', 'Information Gathering',\n",
       "       'Exploits', 'Other', 'Normal', 'Normal', 'Other',\n",
       "       'Information Gathering', 'Denial of Service', 'Other', 'Exploits',\n",
       "       'Information Gathering', 'Information Gathering', 'Exploits',\n",
       "       'Denial of Service', 'Normal', 'Malware'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "label_encoder.inverse_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
